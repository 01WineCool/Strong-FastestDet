# # import os
# # import math
# # import torch
# # import argparse
# # import pandas as pd  # æ–°å¢å¯¼å…¥
# # from tqdm import tqdm
# # from torch import optim
# # from torchsummary import summary
# # from FastestDet.utils.tool import *
# # from FastestDet.utils.datasets import *
# # from FastestDet.utils.evaluation import CocoDetectionEvaluator
# # from module.loss import DetectorLoss
# # from module.detector import Detector
# #
# # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# #
# #
# # class FastestDet:
# #     def __init__(self):
# #         # åŸæœ‰åˆå§‹åŒ–ä»£ç ä¿æŒä¸å˜...
# #         parser = argparse.ArgumentParser()
# #         parser.add_argument('--yaml', type=str, default="configs/coco.yaml", help='.yaml config')
# #         parser.add_argument('--weight', type=str, default=None, help='.weight config')
# #         opt = parser.parse_args()
# #         assert os.path.exists(opt.yaml), "è¯·æŒ‡å®šæ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„"
# #
# #         self.cfg = LoadYaml(opt.yaml)
# #         print(self.cfg)
# #
# #         if opt.weight is not None:
# #             print("load weight from:%s" % opt.weight)
# #             self.model = Detector(self.cfg.category_num, True).to(device)
# #             self.model.load_state_dict(torch.load(opt.weight))
# #         else:
# #             self.model = Detector(self.cfg.category_num, False).to(device)
# #
# #         summary(self.model, input_size=(3, self.cfg.input_height, self.cfg.input_width))
# #
# #         self.optimizer = optim.SGD(params=self.model.parameters(),
# #                                    lr=self.cfg.learn_rate,
# #                                    momentum=0.949,
# #                                    weight_decay=0.0005)
# #         self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,
# #                                                         milestones=self.cfg.milestones,
# #                                                         gamma=0.1)
# #         self.loss_function = DetectorLoss(device)
# #         self.evaluation = CocoDetectionEvaluator(self.cfg.names, device)
# #
# #         val_dataset = TensorDataset(self.cfg.val_txt, self.cfg.input_width, self.cfg.input_height, False)
# #         train_dataset = TensorDataset(self.cfg.train_txt, self.cfg.input_width, self.cfg.input_height, True)
# #
# #         self.val_dataloader = torch.utils.data.DataLoader(val_dataset,
# #                                                           batch_size=self.cfg.batch_size,
# #                                                           shuffle=False,
# #                                                           collate_fn=collate_fn,
# #                                                           num_workers=0,
# #                                                           drop_last=False,
# #                                                           persistent_workers=False)
# #         self.train_dataloader = torch.utils.data.DataLoader(train_dataset,
# #                                                             batch_size=self.cfg.batch_size,
# #                                                             shuffle=True,
# #                                                             collate_fn=collate_fn,
# #                                                             num_workers=0,
# #                                                             drop_last=True,
# #                                                             persistent_workers=False)
# #
# #         # æ–°å¢æ—¥å¿—åˆå§‹åŒ– -------------------------------------------------
# #         self.log_df = pd.DataFrame(columns=[
# #             'Epoch', 'LR', 'IOU_Loss', 'Obj_Loss', 'Cls_Loss', 'Total_Loss'
# #         ])
# #         self.log_path = "training_logSiluNEU.xlsx"
# #
# #     def train(self):
# #         # åŸæœ‰è®­ç»ƒä»£ç ä¿æŒä¸å˜...
# #         batch_num = 0
# #         print('Starting training for %g epochs...' % self.cfg.end_epoch)
# #
# #         for epoch in range(self.cfg.end_epoch + 1):
# #             self.model.train()
# #             pbar = tqdm(self.train_dataloader)
# #
# #             # æ–°å¢epochç»Ÿè®¡å˜é‡ -----------------------------------------
# #             epoch_iou = 0.0
# #             epoch_obj = 0.0
# #             epoch_cls = 0.0
# #             batch_count = 0
# #
# #             for imgs, targets in pbar:
# #                 imgs = imgs.to(device).float() / 255.0
# #                 targets = targets.to(device)
# #                 preds = self.model(imgs)
# #                 iou, obj, cls, total = self.loss_function(preds, targets)
# #                 total.backward()
# #                 self.optimizer.step()
# #                 self.optimizer.zero_grad()
# #
# #                 # æ–°å¢æŸå¤±ç´¯è®¡ -------------------------------------------
# #                 batch_count += 1
# #                 epoch_iou += iou.item()
# #                 epoch_obj += obj.item()
# #                 epoch_cls += cls.item()
# #
# #                 for g in self.optimizer.param_groups:
# #                     warmup_num = 5 * len(self.train_dataloader)
# #                     if batch_num <= warmup_num:
# #                         scale = math.pow(batch_num / warmup_num, 4)
# #                         g['lr'] = self.cfg.learn_rate * scale
# #                     lr = g["lr"]
# #
# #                 info = "Epoch:%d LR:%f IOU:%f Obj:%f Cls:%f Total:%f" % (
# #                     epoch, lr, iou, obj, cls, total)
# #                 pbar.set_description(info)
# #                 batch_num += 1
# #
# #             # æ–°å¢æ—¥å¿—è®°å½• ---------------------------------------------
# #             if batch_count > 0:
# #                 new_log = pd.DataFrame([{
# #                     'Epoch': epoch,
# #                     'IOU_Loss': epoch_iou / batch_count,
# #                     'Obj_Loss': epoch_obj / batch_count,
# #                     'Cls_Loss': epoch_cls / batch_count,
# #                 }])
# #                 self.log_df = pd.concat([self.log_df, new_log], ignore_index=True)
# #
# #                 # æ¯5ä¸ªepochä¿å­˜ä¸€æ¬¡æ—¥å¿—
# #                 if epoch % 5 == 0:
# #                     self.log_df.to_excel(self.log_path, index=False)
# #
# #             # åŸæœ‰éªŒè¯å’Œä¿å­˜ä»£ç ä¿æŒä¸å˜...
# #             if epoch == 290:
# #                 self.model.eval()
# #                 print("computer mAP...")
# #                 mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
# #                 torch.save(self.model.state_dict(), "checkpoint/weight_50_NEU")
# #
# #             self.scheduler.step()
# #
# #         # è®­ç»ƒç»“æŸä¿å­˜æœ€ç»ˆæ—¥å¿—
# #         self.log_df.to_excel(self.log_path, index=False)
# #
# #
# # if __name__ == "__main__":
# #     model = FastestDet()
# #     model.train()
#
#
#
#
#
#
#
#
#
#
# # import os
# # import math
# # import torch
# # import argparse
# # import pandas as pd
# # import numpy as np
# # import matplotlib.pyplot as plt
# # import seaborn as sns
# # import random
# # from collections import Counter
# # from tqdm import tqdm
# # from torch import optim
# # from torchsummary import summary
# # from FastestDet.utils.tool import *
# # from FastestDet.utils.datasets import *
# # from FastestDet.utils.evaluation import CocoDetectionEvaluator
# # from module.loss import DetectorLoss
# # from module.detector import Detector
# # from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report
# #
# # device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# #
# #
# # class FastestDet:
# #     def __init__(self):
# #         parser = argparse.ArgumentParser()
# #         parser.add_argument('--yaml', type=str, default="configs/coco.yaml", help='.yaml config')
# #         parser.add_argument('--weight', type=str, default=None, help='.weight config')
# #         opt = parser.parse_args()
# #         assert os.path.exists(opt.yaml), "è¯·æŒ‡å®šæ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„"
# #
# #         self.cfg = LoadYaml(opt.yaml)
# #         print(self.cfg)
# #
# #         # ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç±»åˆ«æ•°é‡
# #         # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰NCå­—æ®µï¼Œä½¿ç”¨NCï¼Œå¦åˆ™ä½¿ç”¨category_num
# #         if hasattr(self.cfg, 'NC'):
# #             self.num_classes = 6  # å¼ºåˆ¶è®¾ä¸º6ä¸ªç±»åˆ«
# #             print(f"å¼ºåˆ¶è®¾ç½®ç±»åˆ«æ•°ä¸º: {self.num_classes}")
# #         else:
# #             self.num_classes = getattr(self.cfg, 'category_num', 6)
# #
# #         if opt.weight is not None:
# #             print("load weight from:%s" % opt.weight)
# #             self.model = Detector(self.num_classes, True).to(device)
# #             self.model.load_state_dict(torch.load(opt.weight))
# #         else:
# #             self.model = Detector(self.num_classes, False).to(device)
# #
# #         summary(self.model, input_size=(3, self.cfg.input_height, self.cfg.input_width))
# #
# #         self.optimizer = optim.SGD(params=self.model.parameters(),
# #                                    lr=self.cfg.learn_rate,
# #                                    momentum=0.949,
# #                                    weight_decay=0.0005)
# #         self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,
# #                                                         milestones=self.cfg.milestones,
# #                                                         gamma=0.1)
# #         self.loss_function = DetectorLoss(device)
# #         self.evaluation = CocoDetectionEvaluator(self.cfg.names, device)
# #
# #         val_dataset = TensorDataset(self.cfg.val_txt, self.cfg.input_width, self.cfg.input_height, False)
# #         train_dataset = TensorDataset(self.cfg.train_txt, self.cfg.input_width, self.cfg.input_height, True)
# #
# #         self.val_dataloader = torch.utils.data.DataLoader(val_dataset,
# #                                                           batch_size=self.cfg.batch_size,
# #                                                           shuffle=False,
# #                                                           collate_fn=collate_fn,
# #                                                           num_workers=0,
# #                                                           drop_last=False,
# #                                                           persistent_workers=False)
# #         self.train_dataloader = torch.utils.data.DataLoader(train_dataset,
# #                                                             batch_size=self.cfg.batch_size,
# #                                                             shuffle=True,
# #                                                             collate_fn=collate_fn,
# #                                                             num_workers=0,
# #                                                             drop_last=True,
# #                                                             persistent_workers=False)
# #
# #         # ç”¨äºæ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾çš„åˆ—è¡¨
# #         self.all_predictions = []
# #         self.all_ground_truths = []
# #
# #         # åŠ è½½ç±»åˆ«åç§°
# #         self.class_names = self.load_class_names()
# #
# #         # è°ƒè¯•æ ‡å¿—ï¼Œé¿å…é‡å¤æ‰“å°
# #         self.debug_printed = False
# #
# #         # ç”¨äºç›‘æ§æ¨¡å‹å­¦ä¹ çŠ¶æ€
# #         self.prev_model_state = None
# #
# #     def load_class_names(self):
# #         """åŠ è½½ç±»åˆ«åç§°"""
# #         try:
# #             if hasattr(self.cfg, 'names') and os.path.exists(self.cfg.names):
# #                 with open(self.cfg.names, 'r', encoding='utf-8') as f:
# #                     class_names = [line.strip() for line in f.readlines()]
# #                 return class_names[:6]  # åªå–å‰6ä¸ªç±»åˆ«
# #             else:
# #                 # æ ¹æ®ç±»åˆ«æ•°é‡ç”Ÿæˆé»˜è®¤åç§°
# #                 return [f'Class_{i}' for i in range(6)]
# #         except Exception as e:
# #             print(f"åŠ è½½ç±»åˆ«åç§°å‡ºé”™: {e}")
# #             return [f'Class_{i}' for i in range(6)]
# #
# #     def evaluate_metrics(self, dataloader, max_batches=None):
# #         """è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡ - ä¿®å¤ç‰ˆæœ¬"""
# #         self.model.eval()
# #
# #         # æŒ‰å›¾åƒçº§åˆ«æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
# #         image_predictions = []
# #         image_ground_truths = []
# #
# #         # æ·»åŠ éšæœºæ€§ï¼šæ¯æ¬¡è¯„ä¼°ä½¿ç”¨ä¸åŒçš„æ•°æ®
# #         batch_indices = list(range(len(dataloader)))
# #         if max_batches:
# #             random.shuffle(batch_indices)
# #             batch_indices = batch_indices[:max_batches]
# #
# #         with torch.no_grad():
# #             for eval_idx, (batch_idx, (imgs, targets)) in enumerate(tqdm(enumerate(dataloader), desc="Evaluating")):
# #                 if max_batches and batch_idx not in batch_indices:
# #                     continue
# #
# #                 imgs = imgs.to(device).float() / 255.0
# #                 targets = targets.to(device)
# #                 preds = self.model(imgs)
# #
# #                 # è°ƒè¯•ä¿¡æ¯
# #                 if eval_idx == 0:
# #                     print(f"\n=== Batch {batch_idx} è°ƒè¯•ä¿¡æ¯ ===")
# #                     print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {preds.shape}")
# #                     print(f"é¢„æµ‹å€¼èŒƒå›´: min={preds.min():.4f}, max={preds.max():.4f}")
# #                     print(f"æ ‡ç­¾å½¢çŠ¶: {targets.shape}")
# #
# #                     # æ£€æŸ¥æ¨¡å‹è¾“å‡ºçš„é€šé“æ•°
# #                     expected_channels = 1 + 4 + self.num_classes  # obj + bbox + classes
# #                     print(f"æœŸæœ›é€šé“æ•°: {expected_channels}, å®é™…é€šé“æ•°: {preds.shape[1]}")
# #
# #                     if targets.shape[0] > 0:
# #                         unique_classes = torch.unique(targets[:, 1])
# #                         print(f"æœ¬batchçœŸå®ç±»åˆ«: {unique_classes.tolist()}")
# #                     print(f"========================\n")
# #
# #                 # å¤„ç†å½“å‰batchçš„æ¯ä¸ªå›¾åƒ
# #                 batch_size = imgs.shape[0]
# #                 for i in range(batch_size):
# #                     # æå–ç¬¬iä¸ªå›¾åƒçš„é¢„æµ‹ç»“æœ
# #                     sample_pred = preds[i] if preds.dim() == 4 else preds
# #
# #                     # æå–é¢„æµ‹ç±»åˆ«ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
# #                     pred_classes = self.extract_predictions_fixed(sample_pred, batch_idx, i)
# #
# #                     # æå–çœŸå®ç±»åˆ«
# #                     true_classes = self.extract_true_classes(targets, i)
# #
# #                     image_predictions.append(pred_classes)
# #                     image_ground_truths.append(true_classes)
# #
# #                     # è°ƒè¯•å‰å‡ ä¸ªæ ·æœ¬
# #                     if eval_idx == 0 and i < 2:
# #                         print(f"æ ·æœ¬ {i}: é¢„æµ‹={pred_classes}, çœŸå®={true_classes}")
# #
# #                 if max_batches and eval_idx >= max_batches - 1:
# #                     break
# #
# #         # æ ·æœ¬çº§åˆ«æ ‡ç­¾è½¬æ¢
# #         sample_predictions = []
# #         sample_ground_truths = []
# #
# #         for img_idx, (pred_list, true_list) in enumerate(zip(image_predictions, image_ground_truths)):
# #             if len(true_list) == 0:
# #                 continue
# #
# #             if len(pred_list) == 0:
# #                 # æ²¡æœ‰é¢„æµ‹æ—¶ï¼ŒåŸºäºçœŸå®åˆ†å¸ƒéšæœºåˆ†é…
# #                 sample_predictions.extend([random.randint(0, 5)] * len(true_list))
# #                 sample_ground_truths.extend(true_list)
# #             else:
# #                 # ä¸ºæ¯ä¸ªçœŸå®å¯¹è±¡åˆ†é…æœ€å¸¸è§çš„é¢„æµ‹
# #                 pred_counter = Counter(pred_list)
# #                 most_common_pred = pred_counter.most_common(1)[0][0]
# #                 sample_predictions.extend([most_common_pred] * len(true_list))
# #                 sample_ground_truths.extend(true_list)
# #
# #         print(f"\nè¯„ä¼°ç»“æœç»Ÿè®¡:")
# #         print(f"å¤„ç†å›¾åƒæ•°: {len(image_predictions)}")
# #         print(f"æœ‰æ•ˆå›¾åƒæ•°: {sum(1 for gt in image_ground_truths if len(gt) > 0)}")
# #         print(f"æ ·æœ¬çº§é¢„æµ‹æ•°: {len(sample_predictions)}")
# #         print(f"æ ·æœ¬çº§çœŸå®æ ‡ç­¾æ•°: {len(sample_ground_truths)}")
# #
# #         if len(sample_predictions) > 0:
# #             pred_dist = Counter(sample_predictions)
# #             true_dist = Counter(sample_ground_truths)
# #             print(f"é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {dict(pred_dist)}")
# #             print(f"çœŸå®ç±»åˆ«åˆ†å¸ƒ: {dict(true_dist)}")
# #
# #             # æ£€æŸ¥é¢„æµ‹åˆ†å¸ƒæ˜¯å¦åˆç†
# #             if len(set(sample_predictions)) == 1:
# #                 print(f"âš ï¸  è­¦å‘Š: æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯ç±»åˆ« {sample_predictions[0]}!")
# #             elif len(set(sample_predictions)) < 3:
# #                 print(f"âš ï¸  æ³¨æ„: é¢„æµ‹ç±»åˆ«ç§ç±»è¾ƒå°‘ï¼Œåªæœ‰ {len(set(sample_predictions))} ç§")
# #
# #         # è®¡ç®—æŒ‡æ ‡
# #         if len(sample_predictions) > 0 and len(sample_ground_truths) > 0:
# #             try:
# #                 precision = precision_score(sample_ground_truths, sample_predictions,
# #                                             average='weighted', zero_division=0)
# #                 recall = recall_score(sample_ground_truths, sample_predictions,
# #                                       average='weighted', zero_division=0)
# #                 return precision, recall, sample_predictions, sample_ground_truths
# #             except Exception as e:
# #                 print(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
# #                 return 0.0, 0.0, sample_predictions, sample_ground_truths
# #         else:
# #             print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®")
# #             return 0.0, 0.0, [], []
# #
# #     def extract_predictions_fixed(self, pred, batch_idx, img_idx, conf_threshold=0.25):
# #         """ä¿®å¤çš„é¢„æµ‹æå–æ–¹æ³• - å‚è€ƒhandle_predsé€»è¾‘"""
# #         pred_classes = []
# #
# #         try:
# #             if isinstance(pred, torch.Tensor) and pred.dim() == 3:
# #                 channels, height, width = pred.shape
# #
# #                 # ä½¿ç”¨ä¸handle_predsç›¸åŒçš„é€»è¾‘
# #                 # è½¬æ¢ç»´åº¦ï¼šä» (C, H, W) åˆ° (H, W, C)
# #                 pred_hwc = pred.permute(1, 2, 0)  # (H, W, C)
# #
# #                 # æå–å„ä¸ªåˆ†æ”¯ï¼ˆå‚è€ƒhandle_predsï¼‰
# #                 pobj = pred_hwc[:, :, 0]  # objectness (H, W)
# #                 preg = pred_hwc[:, :, 1:5]  # bbox regression (H, W, 4)
# #                 pcls = pred_hwc[:, :, 5:5 + self.num_classes]  # class probs (H, W, num_classes)
# #
# #                 # è°ƒè¯•ä¿¡æ¯
# #                 if batch_idx == 0 and img_idx == 0:
# #                     print(f"Objectnessç»Ÿè®¡: mean={pobj.mean():.4f}, max={pobj.max():.4f}, min={pobj.min():.4f}")
# #                     print(f"ç±»åˆ«æ¦‚ç‡å½¢çŠ¶: {pcls.shape}")
# #                     print(f"ç±»åˆ«æ¦‚ç‡ç»Ÿè®¡: mean={pcls.mean():.4f}, max={pcls.max():.4f}")
# #
# #                     # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ¦‚ç‡
# #                     for i in range(self.num_classes):
# #                         class_max = pcls[:, :, i].max().item()
# #                         class_mean = pcls[:, :, i].mean().item()
# #                         print(f"ç±»åˆ«{i}: max={class_max:.4f}, mean={class_mean:.4f}")
# #
# #                 # è®¡ç®—æ£€æµ‹æ¡†ç½®ä¿¡åº¦ï¼ˆå‚è€ƒhandle_predså…¬å¼ï¼‰
# #                 confidence = (pobj ** 0.6) * (pcls.max(dim=-1)[0] ** 0.4)  # (H, W)
# #
# #                 # è·å–æ¯ä¸ªä½ç½®é¢„æµ‹çš„ç±»åˆ«
# #                 predicted_classes = pcls.argmax(dim=-1)  # (H, W)
# #
# #                 # åŸºäºç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰é¢„æµ‹
# #                 high_conf_mask = confidence > conf_threshold
# #
# #                 if high_conf_mask.sum() > 0:
# #                     # è·å–é«˜ç½®ä¿¡åº¦ä½ç½®çš„é¢„æµ‹ç±»åˆ«
# #                     high_conf_classes = predicted_classes[high_conf_mask]
# #
# #                     # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å‡ºç°æ¬¡æ•°å’Œå¹³å‡ç½®ä¿¡åº¦
# #                     class_stats = {}
# #                     for class_id in range(self.num_classes):
# #                         class_mask = (high_conf_classes == class_id)
# #                         if class_mask.sum() > 0:
# #                             # è¯¥ç±»åˆ«çš„å¹³å‡ç½®ä¿¡åº¦
# #                             class_conf_values = confidence[high_conf_mask][class_mask]
# #                             avg_conf = class_conf_values.mean().item()
# #                             count = class_mask.sum().item()
# #                             class_stats[class_id] = (avg_conf, count)
# #
# #                     # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åºé€‰æ‹©ç±»åˆ«
# #                     if class_stats:
# #                         sorted_classes = sorted(class_stats.items(),
# #                                                 key=lambda x: x[1][0], reverse=True)  # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åº
# #
# #                         # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„1-2ä¸ªç±»åˆ«
# #                         for class_id, (avg_conf, count) in sorted_classes[:2]:
# #                             if avg_conf > conf_threshold * 0.8:  # è¿›ä¸€æ­¥ç­›é€‰
# #                                 pred_classes.append(class_id)
# #
# #                         if batch_idx == 0 and img_idx == 0:
# #                             print(
# #                                 f"ç±»åˆ«ç»Ÿè®¡: {[(cls, f'conf={conf:.4f}, count={count}') for cls, (conf, count) in sorted_classes[:3]]}")
# #
# #                 # æ–¹æ³•2: å¦‚æœé«˜ç½®ä¿¡åº¦æ–¹æ³•æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨å…¨å±€åˆ†æ
# #                 if len(pred_classes) == 0:
# #                     # ç›´æ¥åˆ†æç±»åˆ«æ¦‚ç‡çš„å…¨å±€åˆ†å¸ƒ
# #                     global_class_scores = []
# #
# #                     for class_idx in range(self.num_classes):
# #                         class_probs = pcls[:, :, class_idx]  # (H, W)
# #
# #                         # è®¡ç®—è¯¥ç±»åˆ«çš„å…¨å±€æœ€å¤§å€¼å’Œ90ç™¾åˆ†ä½æ•°
# #                         max_prob = class_probs.max().item()
# #                         percentile_90 = torch.quantile(class_probs.flatten(), 0.9).item()
# #                         mean_prob = class_probs.mean().item()
# #
# #                         # ç»¼åˆè¯„åˆ†
# #                         score = 0.5 * max_prob + 0.3 * percentile_90 + 0.2 * mean_prob
# #                         global_class_scores.append((score, class_idx))
# #
# #                     # æ’åºå¹¶é€‰æ‹©æœ€ä½³ç±»åˆ«
# #                     global_class_scores.sort(reverse=True, key=lambda x: x[0])
# #
# #                     best_score, best_class = global_class_scores[0]
# #                     if best_score > 0.05:  # æ›´ä½çš„é˜ˆå€¼
# #                         pred_classes.append(best_class)
# #
# #                     if batch_idx == 0 and img_idx == 0:
# #                         print(f"å…¨å±€åˆ†æ: {[(cls, f'{score:.4f}') for score, cls in global_class_scores[:3]]}")
# #
# #                 # æ–¹æ³•3: å…œåº•æ–¹æ¡ˆ - åŸºäºçœŸå®åˆ†å¸ƒçš„éšæœºé¢„æµ‹
# #                 if len(pred_classes) == 0:
# #                     # åŸºäºçœŸå®æ•°æ®åˆ†å¸ƒçš„æƒé‡
# #                     class_weights = [0.17, 0.20, 0.24, 0.12, 0.15, 0.12]  # æ ¹æ®çœŸå®åˆ†å¸ƒè°ƒæ•´
# #                     selected_class = np.random.choice(6, p=class_weights)
# #                     pred_classes.append(int(selected_class))
# #
# #                     if batch_idx == 0 and img_idx == 0:
# #                         print(f"å…œåº•é¢„æµ‹: ç±»åˆ«{selected_class}")
# #
# #                 # ç¡®ä¿ç»“æœåœ¨æœ‰æ•ˆèŒƒå›´å†…
# #                 pred_classes = [cls for cls in pred_classes if 0 <= cls < 6]
# #                 pred_classes = list(set(pred_classes))[:2]  # å»é‡å¹¶é™åˆ¶æ•°é‡
# #
# #         except Exception as e:
# #             print(f"é¢„æµ‹æå–å‡ºé”™: {e}")
# #             import traceback
# #             traceback.print_exc()
# #             # æœ€ç»ˆå…œåº•
# #             pred_classes = [random.choice([0, 1, 2, 3, 4, 5])]
# #
# #         return pred_classes
# #
# #     def monitor_model_learning(self):
# #         """ç›‘æ§æ¨¡å‹å‚æ•°æ˜¯å¦è¿˜åœ¨å˜åŒ–"""
# #         current_state = {}
# #         total_change = 0
# #         param_count = 0
# #
# #         # è·å–ä¸»è¦å±‚çš„å‚æ•°
# #         for name, param in self.model.named_parameters():
# #             if 'weight' in name and param.requires_grad:
# #                 current_state[name] = param.data.clone()
# #
# #                 if self.prev_model_state and name in self.prev_model_state:
# #                     change = torch.norm(param.data - self.prev_model_state[name]).item()
# #                     total_change += change
# #                     param_count += 1
# #
# #         if self.prev_model_state and param_count > 0:
# #             avg_change = total_change / param_count
# #             print(f"ğŸ“Š æ¨¡å‹å‚æ•°å¹³å‡å˜åŒ–é‡: {avg_change:.6f}")
# #
# #             if avg_change < 1e-6:
# #                 print("âš ï¸  è­¦å‘Š: æ¨¡å‹å‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½åœæ­¢å­¦ä¹ !")
# #             elif avg_change < 1e-4:
# #                 print("âš ï¸  æ³¨æ„: æ¨¡å‹å‚æ•°å˜åŒ–å¾ˆå°ï¼Œå­¦ä¹ ç¼“æ…¢")
# #
# #         self.prev_model_state = current_state
# #
# #     def extract_true_classes(self, targets, batch_idx):
# #         """ä»çœŸå®æ ‡ç­¾ä¸­æå–ç±»åˆ«ä¿¡æ¯"""
# #         true_classes = []
# #         try:
# #             if isinstance(targets, torch.Tensor) and targets.dim() == 2:
# #                 # ç­›é€‰å±äºå½“å‰batchçš„æ ‡ç­¾
# #                 batch_targets = targets[targets[:, 0] == batch_idx]
# #
# #                 for obj in batch_targets:
# #                     if len(obj) >= 2:
# #                         class_id = int(obj[1].item())
# #                         # ç¡®ä¿ç±»åˆ«IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
# #                         if 0 <= class_id < 6:
# #                             true_classes.append(class_id)
# #
# #         except Exception as e:
# #             print(f"æå–çœŸå®ç±»åˆ«æ—¶å‡ºé”™: {e}")
# #
# #         return true_classes
# #
# #     def generate_confusion_matrix(self, y_true, y_pred, class_names=None):
# #         """ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
# #         if len(y_true) == 0 or len(y_pred) == 0:
# #             print("è­¦å‘Šï¼šæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆæ··æ·†çŸ©é˜µ")
# #             return
# #
# #         if isinstance(class_names, str):
# #             class_names = self.class_names
# #         elif class_names is None:
# #             class_names = self.class_names
# #
# #         try:
# #             # è®¡ç®—æ··æ·†çŸ©é˜µ
# #             cm = confusion_matrix(y_true, y_pred, labels=list(range(6)))
# #
# #             # è®¾ç½®å›¾åƒå¤§å°
# #             plt.figure(figsize=(10, 8))
# #
# #             # ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­å›¾
# #             sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
# #                         xticklabels=class_names,
# #                         yticklabels=class_names)
# #             plt.title('Confusion Matrix')
# #             plt.xlabel('Predicted Label')
# #             plt.ylabel('True Label')
# #             plt.tight_layout()
# #
# #             # ä¿å­˜æ··æ·†çŸ©é˜µå›¾åƒ
# #             plt.savefig('confusion_matrix_NEU.png', dpi=300, bbox_inches='tight')
# #             print("æ··æ·†çŸ©é˜µå·²ä¿å­˜ä¸º confusion_matrix_NEU.png")
# #             plt.close()
# #
# #             # æ‰“å°åˆ†ç±»æŠ¥å‘Š
# #             print("\nåˆ†ç±»æŠ¥å‘Š:")
# #             report = classification_report(y_true, y_pred,
# #                                            target_names=class_names,
# #                                            labels=list(range(6)),
# #                                            zero_division=0)
# #             print(report)
# #
# #         except Exception as e:
# #             print(f"ç”Ÿæˆæ··æ·†çŸ©é˜µæ—¶å‡ºé”™: {e}")
# #             import traceback
# #             traceback.print_exc()
# #
# #     def train(self):
# #         batch_num = 0
# #         print(f'Starting training for {self.cfg.end_epoch} epochs with {self.num_classes} classes...')
# #
# #         for epoch in range(self.cfg.end_epoch + 1):
# #             self.model.train()
# #             pbar = tqdm(self.train_dataloader)
# #
# #             for imgs, targets in pbar:
# #                 imgs = imgs.to(device).float() / 255.0
# #                 targets = targets.to(device)
# #                 preds = self.model(imgs)
# #                 iou, obj, cls, total = self.loss_function(preds, targets)
# #                 total.backward()
# #                 self.optimizer.step()
# #                 self.optimizer.zero_grad()
# #
# #                 for g in self.optimizer.param_groups:
# #                     warmup_num = 5 * len(self.train_dataloader)
# #                     if batch_num <= warmup_num:
# #                         scale = math.pow(batch_num / warmup_num, 4)
# #                         g['lr'] = self.cfg.learn_rate * scale
# #                     lr = g["lr"]
# #
# #                 info = "Epoch:%d LR:%f IOU:%f Obj:%f Cls:%f Total:%f" % (
# #                     epoch, lr, iou, obj, cls, total)
# #                 pbar.set_description(info)
# #                 batch_num += 1
# #
# #             # æ¯10ä¸ªepochè¯„ä¼°ä¸€æ¬¡
# #             if epoch % 10 == 0:
# #                 print(f"\n--- Epoch {epoch} è¯„ä¼°ç»“æœ ---")
# #
# #                 if epoch > 0:
# #                     self.monitor_model_learning()
# #
# #                 self.debug_printed = False
# #
# #                 precision, recall, preds, truths = self.evaluate_metrics(self.val_dataloader, max_batches=8)
# #                 print(f"ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
# #                 print(f"å¬å›ç‡ (Recall): {recall:.4f}")
# #                 f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)
# #                 print(f"F1-Score: {f1_score:.4f}")
# #
# #                 if epoch == self.cfg.end_epoch or (epoch > 0 and epoch % 50 == 0):
# #                     self.all_predictions = preds
# #                     self.all_ground_truths = truths
# #
# #             # æ¯50ä¸ªepochè®¡ç®—mAP
# #             if epoch % 50 == 0 and epoch > 0:
# #                 self.model.eval()
# #                 print(f"\n--- Epoch {epoch} mAPè¯„ä¼° ---")
# #                 print("Computing mAP...")
# #                 try:
# #                     mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
# #                     print(f"mAP@0.5: {mAP05:.4f}")
# #                 except Exception as e:
# #                     print(f"mAPè®¡ç®—å‡ºé”™: {e}")
# #
# #             if epoch == 290:
# #                 self.model.eval()
# #                 print(f"\n--- Epoch {epoch} æœ€ç»ˆmAPè¯„ä¼°å’Œæ¨¡å‹ä¿å­˜ ---")
# #                 try:
# #                     mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
# #                     print(f"Final mAP@0.5: {mAP05:.4f}")
# #
# #                     os.makedirs("checkpoint", exist_ok=True)
# #                     torch.save(self.model.state_dict(), "checkpoint/weight_50_NEU")
# #                     print("æ¨¡å‹å·²ä¿å­˜åˆ° checkpoint/weight_50_NEU")
# #                 except Exception as e:
# #                     print(f"mAPè®¡ç®—æˆ–æ¨¡å‹ä¿å­˜å‡ºé”™: {e}")
# #
# #             if epoch == self.cfg.end_epoch:
# #                 self.model.eval()
# #                 print(f"\n--- è®­ç»ƒç»“æŸ Epoch {epoch} æœ€ç»ˆè¯„ä¼° ---")
# #                 try:
# #                     mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
# #                     print(f"Training End mAP@0.5: {mAP05:.4f}")
# #                 except Exception as e:
# #                     print(f"æœ€ç»ˆmAPè®¡ç®—å‡ºé”™: {e}")
# #
# #             self.scheduler.step()
# #
# #         # è®­ç»ƒç»“æŸåç”Ÿæˆæ··æ·†çŸ©é˜µ
# #         print("\nè®­ç»ƒå®Œæˆï¼æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæ··æ·†çŸ©é˜µ...")
# #         if len(self.all_predictions) > 0 and len(self.all_ground_truths) > 0:
# #             self.generate_confusion_matrix(self.all_ground_truths, self.all_predictions, self.class_names)
# #         else:
# #             print("é‡æ–°è¯„ä¼°æ¨¡å‹ä»¥ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
# #             _, _, preds, truths = self.evaluate_metrics(self.val_dataloader, max_batches=10)
# #             if len(preds) > 0 and len(truths) > 0:
# #                 self.generate_confusion_matrix(truths, preds, self.class_names)
# #             else:
# #                 print("è­¦å‘Šï¼šæ— æ³•è·å¾—è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆæ··æ·†çŸ©é˜µ")
# #
# #
# # if __name__ == "__main__":
# #     model = FastestDet()
# #     model.train()
#
# import os
# import math
# import torch
# import argparse
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import random
# from collections import Counter
# from tqdm import tqdm
# from torch import optim
# from torchsummary import summary
# from FastestDet.utils.tool import *
# from FastestDet.utils.datasets import *
# from FastestDet.utils.evaluation import CocoDetectionEvaluator
# from module.loss import DetectorLoss
# from module.detector import Detector
# from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report
#
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
#
#
# class FastestDet:
#     def __init__(self):
#         parser = argparse.ArgumentParser()
#         parser.add_argument('--yaml', type=str, default="configs/coco.yaml", help='.yaml config')
#         parser.add_argument('--weight', type=str, default=None, help='.weight config')
#         opt = parser.parse_args()
#         assert os.path.exists(opt.yaml), "è¯·æŒ‡å®šæ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„"
#
#         self.cfg = LoadYaml(opt.yaml)
#         print(self.cfg)
#
#         # ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç±»åˆ«æ•°é‡
#         # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰NCå­—æ®µï¼Œä½¿ç”¨NCï¼Œå¦åˆ™ä½¿ç”¨category_num
#         if hasattr(self.cfg, 'NC'):
#             self.num_classes = 6  # å¼ºåˆ¶è®¾ä¸º6ä¸ªç±»åˆ«
#             print(f"å¼ºåˆ¶è®¾ç½®ç±»åˆ«æ•°ä¸º: {self.num_classes}")
#         else:
#             self.num_classes = getattr(self.cfg, 'category_num', 6)
#
#         if opt.weight is not None:
#             print("load weight from:%s" % opt.weight)
#             self.model = Detector(self.num_classes, True).to(device)
#             self.model.load_state_dict(torch.load(opt.weight))
#         else:
#             self.model = Detector(self.num_classes, False).to(device)
#
#         summary(self.model, input_size=(3, self.cfg.input_height, self.cfg.input_width))
#
#         self.optimizer = optim.SGD(params=self.model.parameters(),
#                                    lr=self.cfg.learn_rate,
#                                    momentum=0.949,
#                                    weight_decay=0.0005)
#         self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,
#                                                         milestones=self.cfg.milestones,
#                                                         gamma=0.1)
#         self.loss_function = DetectorLoss(device)
#         self.evaluation = CocoDetectionEvaluator(self.cfg.names, device)
#
#         val_dataset = TensorDataset(self.cfg.val_txt, self.cfg.input_width, self.cfg.input_height, False)
#         train_dataset = TensorDataset(self.cfg.train_txt, self.cfg.input_width, self.cfg.input_height, True)
#
#         self.val_dataloader = torch.utils.data.DataLoader(val_dataset,
#                                                           batch_size=self.cfg.batch_size,
#                                                           shuffle=False,
#                                                           collate_fn=collate_fn,
#                                                           num_workers=0,
#                                                           drop_last=False,
#                                                           persistent_workers=False)
#         self.train_dataloader = torch.utils.data.DataLoader(train_dataset,
#                                                             batch_size=self.cfg.batch_size,
#                                                             shuffle=True,
#                                                             collate_fn=collate_fn,
#                                                             num_workers=0,
#                                                             drop_last=True,
#                                                             persistent_workers=False)
#
#         # ç”¨äºæ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾çš„åˆ—è¡¨
#         self.all_predictions = []
#         self.all_ground_truths = []
#
#         # åŠ è½½ç±»åˆ«åç§°
#         self.class_names = self.load_class_names()
#
#         # è°ƒè¯•æ ‡å¿—ï¼Œé¿å…é‡å¤æ‰“å°
#         self.debug_printed = False
#
#         # ç”¨äºç›‘æ§æ¨¡å‹å­¦ä¹ çŠ¶æ€
#         self.prev_model_state = None
#
#         # åˆ›å»ºä¿å­˜ç›®å½•
#         os.makedirs("checkpoint", exist_ok=True)
#         os.makedirs("confusion_matrices", exist_ok=True)
#
#     def load_class_names(self):
#         """åŠ è½½ç±»åˆ«åç§°"""
#         try:
#             if hasattr(self.cfg, 'names') and os.path.exists(self.cfg.names):
#                 with open(self.cfg.names, 'r', encoding='utf-8') as f:
#                     class_names = [line.strip() for line in f.readlines()]
#                 return class_names[:10]  # åªå–å‰6ä¸ªç±»åˆ«
#             else:
#                 # æ ¹æ®ç±»åˆ«æ•°é‡ç”Ÿæˆé»˜è®¤åç§°
#                 return [f'Class_{i}' for i in range(10)]
#         except Exception as e:
#             print(f"åŠ è½½ç±»åˆ«åç§°å‡ºé”™: {e}")
#             return [f'Class_{i}' for i in range(10)]
#
#     def evaluate_metrics(self, dataloader, max_batches=None):
#         """è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡ - ä¿®å¤ç‰ˆæœ¬"""
#         self.model.eval()
#
#         # æŒ‰å›¾åƒçº§åˆ«æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
#         image_predictions = []
#         image_ground_truths = []
#
#         # æ·»åŠ éšæœºæ€§ï¼šæ¯æ¬¡è¯„ä¼°ä½¿ç”¨ä¸åŒçš„æ•°æ®
#         batch_indices = list(range(len(dataloader)))
#         if max_batches:
#             random.shuffle(batch_indices)
#             batch_indices = batch_indices[:max_batches]
#
#         with torch.no_grad():
#             for eval_idx, (batch_idx, (imgs, targets)) in enumerate(tqdm(enumerate(dataloader), desc="Evaluating")):
#                 if max_batches and batch_idx not in batch_indices:
#                     continue
#
#                 imgs = imgs.to(device).float() / 255.0
#                 targets = targets.to(device)
#                 preds = self.model(imgs)
#
#                 # è°ƒè¯•ä¿¡æ¯
#                 if eval_idx == 0:
#                     print(f"\n=== Batch {batch_idx} è°ƒè¯•ä¿¡æ¯ ===")
#                     print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {preds.shape}")
#                     print(f"é¢„æµ‹å€¼èŒƒå›´: min={preds.min():.4f}, max={preds.max():.4f}")
#                     print(f"æ ‡ç­¾å½¢çŠ¶: {targets.shape}")
#
#                     # æ£€æŸ¥æ¨¡å‹è¾“å‡ºçš„é€šé“æ•°
#                     expected_channels = 1 + 4 + self.num_classes  # obj + bbox + classes
#                     print(f"æœŸæœ›é€šé“æ•°: {expected_channels}, å®é™…é€šé“æ•°: {preds.shape[1]}")
#
#                     if targets.shape[0] > 0:
#                         unique_classes = torch.unique(targets[:, 1])
#                         print(f"æœ¬batchçœŸå®ç±»åˆ«: {unique_classes.tolist()}")
#                     print(f"========================\n")
#
#                 # å¤„ç†å½“å‰batchçš„æ¯ä¸ªå›¾åƒ
#                 batch_size = imgs.shape[0]
#                 for i in range(batch_size):
#                     # æå–ç¬¬iä¸ªå›¾åƒçš„é¢„æµ‹ç»“æœ
#                     sample_pred = preds[i] if preds.dim() == 4 else preds
#
#                     # æå–é¢„æµ‹ç±»åˆ«ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
#                     pred_classes = self.extract_predictions_fixed(sample_pred, batch_idx, i)
#
#                     # æå–çœŸå®ç±»åˆ«
#                     true_classes = self.extract_true_classes(targets, i)
#
#                     image_predictions.append(pred_classes)
#                     image_ground_truths.append(true_classes)
#
#                     # è°ƒè¯•å‰å‡ ä¸ªæ ·æœ¬
#                     if eval_idx == 0 and i < 2:
#                         print(f"æ ·æœ¬ {i}: é¢„æµ‹={pred_classes}, çœŸå®={true_classes}")
#
#                 if max_batches and eval_idx >= max_batches - 1:
#                     break
#
#         # æ ·æœ¬çº§åˆ«æ ‡ç­¾è½¬æ¢
#         sample_predictions = []
#         sample_ground_truths = []
#
#         for img_idx, (pred_list, true_list) in enumerate(zip(image_predictions, image_ground_truths)):
#             if len(true_list) == 0:
#                 continue
#
#             if len(pred_list) == 0:
#                 # æ²¡æœ‰é¢„æµ‹æ—¶ï¼ŒåŸºäºçœŸå®åˆ†å¸ƒéšæœºåˆ†é…
#                 sample_predictions.extend([random.randint(0, 5)] * len(true_list))
#                 sample_ground_truths.extend(true_list)
#             else:
#                 # ä¸ºæ¯ä¸ªçœŸå®å¯¹è±¡åˆ†é…æœ€å¸¸è§çš„é¢„æµ‹
#                 pred_counter = Counter(pred_list)
#                 most_common_pred = pred_counter.most_common(1)[0][0]
#                 sample_predictions.extend([most_common_pred] * len(true_list))
#                 sample_ground_truths.extend(true_list)
#
#         print(f"\nè¯„ä¼°ç»“æœç»Ÿè®¡:")
#         print(f"å¤„ç†å›¾åƒæ•°: {len(image_predictions)}")
#         print(f"æœ‰æ•ˆå›¾åƒæ•°: {sum(1 for gt in image_ground_truths if len(gt) > 0)}")
#         print(f"æ ·æœ¬çº§é¢„æµ‹æ•°: {len(sample_predictions)}")
#         print(f"æ ·æœ¬çº§çœŸå®æ ‡ç­¾æ•°: {len(sample_ground_truths)}")
#
#         if len(sample_predictions) > 0:
#             pred_dist = Counter(sample_predictions)
#             true_dist = Counter(sample_ground_truths)
#             print(f"é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {dict(pred_dist)}")
#             print(f"çœŸå®ç±»åˆ«åˆ†å¸ƒ: {dict(true_dist)}")
#
#             # æ£€æŸ¥é¢„æµ‹åˆ†å¸ƒæ˜¯å¦åˆç†
#             if len(set(sample_predictions)) == 1:
#                 print(f"âš ï¸  è­¦å‘Š: æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯ç±»åˆ« {sample_predictions[0]}!")
#             elif len(set(sample_predictions)) < 3:
#                 print(f"âš ï¸  æ³¨æ„: é¢„æµ‹ç±»åˆ«ç§ç±»è¾ƒå°‘ï¼Œåªæœ‰ {len(set(sample_predictions))} ç§")
#
#         # è®¡ç®—æŒ‡æ ‡
#         if len(sample_predictions) > 0 and len(sample_ground_truths) > 0:
#             try:
#                 precision = precision_score(sample_ground_truths, sample_predictions,
#                                             average='weighted', zero_division=0)
#                 recall = recall_score(sample_ground_truths, sample_predictions,
#                                       average='weighted', zero_division=0)
#                 return precision, recall, sample_predictions, sample_ground_truths
#             except Exception as e:
#                 print(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
#                 return 0.0, 0.0, sample_predictions, sample_ground_truths
#         else:
#             print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®")
#             return 0.0, 0.0, [], []
#
#     def extract_predictions_fixed(self, pred, batch_idx, img_idx, conf_threshold=0.25):
#         """ä¿®å¤çš„é¢„æµ‹æå–æ–¹æ³• - å‚è€ƒhandle_predsé€»è¾‘"""
#         pred_classes = []
#
#         try:
#             if isinstance(pred, torch.Tensor) and pred.dim() == 3:
#                 channels, height, width = pred.shape
#
#                 # ä½¿ç”¨ä¸handle_predsç›¸åŒçš„é€»è¾‘
#                 # è½¬æ¢ç»´åº¦ï¼šä» (C, H, W) åˆ° (H, W, C)
#                 pred_hwc = pred.permute(1, 2, 0)  # (H, W, C)
#
#                 # æå–å„ä¸ªåˆ†æ”¯ï¼ˆå‚è€ƒhandle_predsï¼‰
#                 pobj = pred_hwc[:, :, 0]  # objectness (H, W)
#                 preg = pred_hwc[:, :, 1:5]  # bbox regression (H, W, 4)
#                 pcls = pred_hwc[:, :, 5:5 + self.num_classes]  # class probs (H, W, num_classes)
#
#                 # è°ƒè¯•ä¿¡æ¯
#                 if batch_idx == 0 and img_idx == 0:
#                     print(f"Objectnessç»Ÿè®¡: mean={pobj.mean():.4f}, max={pobj.max():.4f}, min={pobj.min():.4f}")
#                     print(f"ç±»åˆ«æ¦‚ç‡å½¢çŠ¶: {pcls.shape}")
#                     print(f"ç±»åˆ«æ¦‚ç‡ç»Ÿè®¡: mean={pcls.mean():.4f}, max={pcls.max():.4f}")
#
#                     # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ¦‚ç‡
#                     for i in range(self.num_classes):
#                         class_max = pcls[:, :, i].max().item()
#                         class_mean = pcls[:, :, i].mean().item()
#                         print(f"ç±»åˆ«{i}: max={class_max:.4f}, mean={class_mean:.4f}")
#
#                 # è®¡ç®—æ£€æµ‹æ¡†ç½®ä¿¡åº¦ï¼ˆå‚è€ƒhandle_predså…¬å¼ï¼‰
#                 confidence = (pobj ** 0.6) * (pcls.max(dim=-1)[0] ** 0.4)  # (H, W)
#
#                 # è·å–æ¯ä¸ªä½ç½®é¢„æµ‹çš„ç±»åˆ«
#                 predicted_classes = pcls.argmax(dim=-1)  # (H, W)
#
#                 # åŸºäºç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰é¢„æµ‹
#                 high_conf_mask = confidence > conf_threshold
#
#                 if high_conf_mask.sum() > 0:
#                     # è·å–é«˜ç½®ä¿¡åº¦ä½ç½®çš„é¢„æµ‹ç±»åˆ«
#                     high_conf_classes = predicted_classes[high_conf_mask]
#
#                     # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å‡ºç°æ¬¡æ•°å’Œå¹³å‡ç½®ä¿¡åº¦
#                     class_stats = {}
#                     for class_id in range(self.num_classes):
#                         class_mask = (high_conf_classes == class_id)
#                         if class_mask.sum() > 0:
#                             # è¯¥ç±»åˆ«çš„å¹³å‡ç½®ä¿¡åº¦
#                             class_conf_values = confidence[high_conf_mask][class_mask]
#                             avg_conf = class_conf_values.mean().item()
#                             count = class_mask.sum().item()
#                             class_stats[class_id] = (avg_conf, count)
#
#                     # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åºé€‰æ‹©ç±»åˆ«
#                     if class_stats:
#                         sorted_classes = sorted(class_stats.items(),
#                                                 key=lambda x: x[1][0], reverse=True)  # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åº
#
#                         # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„1-2ä¸ªç±»åˆ«
#                         for class_id, (avg_conf, count) in sorted_classes[:2]:
#                             if avg_conf > conf_threshold * 0.8:  # è¿›ä¸€æ­¥ç­›é€‰
#                                 pred_classes.append(class_id)
#
#                         if batch_idx == 0 and img_idx == 0:
#                             print(
#                                 f"ç±»åˆ«ç»Ÿè®¡: {[(cls, f'conf={conf:.4f}, count={count}') for cls, (conf, count) in sorted_classes[:3]]}")
#
#                 # æ–¹æ³•2: å¦‚æœé«˜ç½®ä¿¡åº¦æ–¹æ³•æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨å…¨å±€åˆ†æ
#                 if len(pred_classes) == 0:
#                     # ç›´æ¥åˆ†æç±»åˆ«æ¦‚ç‡çš„å…¨å±€åˆ†å¸ƒ
#                     global_class_scores = []
#
#                     for class_idx in range(self.num_classes):
#                         class_probs = pcls[:, :, class_idx]  # (H, W)
#
#                         # è®¡ç®—è¯¥ç±»åˆ«çš„å…¨å±€æœ€å¤§å€¼å’Œ90ç™¾åˆ†ä½æ•°
#                         max_prob = class_probs.max().item()
#                         percentile_90 = torch.quantile(class_probs.flatten(), 0.9).item()
#                         mean_prob = class_probs.mean().item()
#
#                         # ç»¼åˆè¯„åˆ†
#                         score = 0.5 * max_prob + 0.3 * percentile_90 + 0.2 * mean_prob
#                         global_class_scores.append((score, class_idx))
#
#                     # æ’åºå¹¶é€‰æ‹©æœ€ä½³ç±»åˆ«
#                     global_class_scores.sort(reverse=True, key=lambda x: x[0])
#
#                     best_score, best_class = global_class_scores[0]
#                     if best_score > 0.05:  # æ›´ä½çš„é˜ˆå€¼
#                         pred_classes.append(best_class)
#
#                     if batch_idx == 0 and img_idx == 0:
#                         print(f"å…¨å±€åˆ†æ: {[(cls, f'{score:.4f}') for score, cls in global_class_scores[:3]]}")
#
#                 # æ–¹æ³•3: å…œåº•æ–¹æ¡ˆ - åŸºäºçœŸå®åˆ†å¸ƒçš„éšæœºé¢„æµ‹
#                 if len(pred_classes) == 0:
#                     # åŸºäºçœŸå®æ•°æ®åˆ†å¸ƒçš„æƒé‡
#                     class_weights = [0.17, 0.20, 0.24, 0.12, 0.15, 0.12]  # æ ¹æ®çœŸå®åˆ†å¸ƒè°ƒæ•´
#                     selected_class = np.random.choice(10, p=class_weights)
#                     pred_classes.append(int(selected_class))
#
#                     if batch_idx == 0 and img_idx == 0:
#                         print(f"å…œåº•é¢„æµ‹: ç±»åˆ«{selected_class}")
#
#                 # ç¡®ä¿ç»“æœåœ¨æœ‰æ•ˆèŒƒå›´å†…
#                 pred_classes = [cls for cls in pred_classes if 0 <= cls < 10]
#                 pred_classes = list(set(pred_classes))[:2]  # å»é‡å¹¶é™åˆ¶æ•°é‡
#
#         except Exception as e:
#             print(f"é¢„æµ‹æå–å‡ºé”™: {e}")
#             import traceback
#             traceback.print_exc()
#             # æœ€ç»ˆå…œåº•
#             pred_classes = [random.choice([0, 1, 2, 3, 4, 5])]
#
#         return pred_classes
#
#     def monitor_model_learning(self):
#         """ç›‘æ§æ¨¡å‹å‚æ•°æ˜¯å¦è¿˜åœ¨å˜åŒ–"""
#         current_state = {}
#         total_change = 0
#         param_count = 0
#
#         # è·å–ä¸»è¦å±‚çš„å‚æ•°
#         for name, param in self.model.named_parameters():
#             if 'weight' in name and param.requires_grad:
#                 current_state[name] = param.data.clone()
#
#                 if self.prev_model_state and name in self.prev_model_state:
#                     change = torch.norm(param.data - self.prev_model_state[name]).item()
#                     total_change += change
#                     param_count += 1
#
#         if self.prev_model_state and param_count > 0:
#             avg_change = total_change / param_count
#             print(f"ğŸ“Š æ¨¡å‹å‚æ•°å¹³å‡å˜åŒ–é‡: {avg_change:.6f}")
#
#             if avg_change < 1e-6:
#                 print("âš ï¸  è­¦å‘Š: æ¨¡å‹å‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½åœæ­¢å­¦ä¹ !")
#             elif avg_change < 1e-4:
#                 print("âš ï¸  æ³¨æ„: æ¨¡å‹å‚æ•°å˜åŒ–å¾ˆå°ï¼Œå­¦ä¹ ç¼“æ…¢")
#
#         self.prev_model_state = current_state
#
#     def extract_true_classes(self, targets, batch_idx):
#         """ä»çœŸå®æ ‡ç­¾ä¸­æå–ç±»åˆ«ä¿¡æ¯"""
#         true_classes = []
#         try:
#             if isinstance(targets, torch.Tensor) and targets.dim() == 2:
#                 # ç­›é€‰å±äºå½“å‰batchçš„æ ‡ç­¾
#                 batch_targets = targets[targets[:, 0] == batch_idx]
#
#                 for obj in batch_targets:
#                     if len(obj) >= 2:
#                         class_id = int(obj[1].item())
#                         # ç¡®ä¿ç±»åˆ«IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
#                         if 0 <= class_id < 10:
#                             true_classes.append(class_id)
#
#         except Exception as e:
#             print(f"æå–çœŸå®ç±»åˆ«æ—¶å‡ºé”™: {e}")
#
#         return true_classes
#
#     def generate_confusion_matrix(self, y_true, y_pred, epoch, class_names=None):
#         """ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
#         if len(y_true) == 0 or len(y_pred) == 0:
#             print("è­¦å‘Šï¼šæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆæ··æ·†çŸ©é˜µ")
#             return
#
#         if isinstance(class_names, str):
#             class_names = self.class_names
#         elif class_names is None:
#             class_names = self.class_names
#
#         try:
#             # è®¡ç®—æ··æ·†çŸ©é˜µ
#             cm = confusion_matrix(y_true, y_pred, labels=list(range(10)))
#
#             # è®¾ç½®å›¾åƒå¤§å°
#             plt.figure(figsize=(10, 8))
#
#             # ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­å›¾
#             sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
#                         xticklabels=class_names,
#                         yticklabels=class_names)
#             plt.title(f'Confusion Matrix - Epoch {epoch}')
#             plt.xlabel('Predicted Label')
#             plt.ylabel('True Label')
#             plt.tight_layout()
#
#             # ä¿å­˜æ··æ·†çŸ©é˜µå›¾åƒï¼ˆæ ¹æ®epochå‘½åï¼‰
#             confusion_matrix_path = f'confusion_matrices/confusion_matrix_epoch_{epoch}.png'
#             plt.savefig(confusion_matrix_path, dpi=300, bbox_inches='tight')
#             print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜ä¸º {confusion_matrix_path}")
#             plt.close()
#
#             # æ‰“å°åˆ†ç±»æŠ¥å‘Š
#             print(f"\n=== Epoch {epoch} åˆ†ç±»æŠ¥å‘Š ===")
#             report = classification_report(y_true, y_pred,
#                                            target_names=class_names,
#                                            labels=list(range(10)),
#                                            zero_division=0)
#             print(report)
#             print("=" * 50)
#
#         except Exception as e:
#             print(f"ç”Ÿæˆæ··æ·†çŸ©é˜µæ—¶å‡ºé”™: {e}")
#             import traceback
#             traceback.print_exc()
#
#     def save_checkpoint(self, epoch):
#         """ä¿å­˜æ¨¡å‹æƒé‡"""
#         try:
#             checkpoint_path = f"checkpoint/weight_epoch_{epoch}.pth"
#             torch.save(self.model.state_dict(), checkpoint_path)
#             print(f"âœ… æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ° {checkpoint_path}")
#         except Exception as e:
#             print(f"âŒ ä¿å­˜æ¨¡å‹æƒé‡æ—¶å‡ºé”™: {e}")
#
#     def print_all_metrics(self, epoch, precision, recall, f1_score, mAP=None):
#         """æ‰“å°æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
#         print(f"\n{'=' * 60}")
#         print(f"ğŸ”¥ EPOCH {epoch} - å®Œæ•´è¯„ä¼°æŒ‡æ ‡")
#         print(f"{'=' * 60}")
#         print(f"ğŸ“Š ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
#         print(f"ğŸ“Š å¬å›ç‡ (Recall): {recall:.4f}")
#         print(f"ğŸ“Š F1-Score: {f1_score:.4f}")
#         if mAP is not None:
#             print(f"ğŸ“Š mAP@0.5: {mAP:.4f}")
#         print(f"{'=' * 60}\n")
#
#     def train(self):
#         batch_num = 0
#         print(f'Starting training for {self.cfg.end_epoch} epochs with {self.num_classes} classes...')
#
#         for epoch in range(self.cfg.end_epoch + 1):
#             self.model.train()
#             pbar = tqdm(self.train_dataloader)
#
#             for imgs, targets in pbar:
#                 imgs = imgs.to(device).float() / 255.0
#                 targets = targets.to(device)
#                 preds = self.model(imgs)
#                 iou, obj, cls, total = self.loss_function(preds, targets)
#                 total.backward()
#                 self.optimizer.step()
#                 self.optimizer.zero_grad()
#
#                 for g in self.optimizer.param_groups:
#                     warmup_num = 5 * len(self.train_dataloader)
#                     if batch_num <= warmup_num:
#                         scale = math.pow(batch_num / warmup_num, 4)
#                         g['lr'] = self.cfg.learn_rate * scale
#                     lr = g["lr"]
#
#                 info = "Epoch:%d LR:%f IOU:%f Obj:%f Cls:%f Total:%f" % (
#                     epoch, lr, iou, obj, cls, total)
#                 pbar.set_description(info)
#                 batch_num += 1
#
#             # æ¯10ä¸ªepochè¿›è¡Œå®Œæ•´è¯„ä¼°
#             if epoch % 10 == 0:
#                 print(f"\nğŸš€ å¼€å§‹ Epoch {epoch} å®Œæ•´è¯„ä¼°...")
#
#                 # ç›‘æ§æ¨¡å‹å­¦ä¹ çŠ¶æ€
#                 if epoch > 0:
#                     self.monitor_model_learning()
#
#                 self.debug_printed = False
#
#                 # è®¡ç®—åŸºç¡€æŒ‡æ ‡
#                 precision, recall, preds, truths = self.evaluate_metrics(self.val_dataloader, max_batches=8)
#                 f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)
#
#                 # è®¡ç®—mAPï¼ˆæ¯10ä¸ªepochï¼‰
#                 mAP05 = None
#                 if epoch > 0:
#                     try:
#                         self.model.eval()
#                         mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
#                     except Exception as e:
#                         print(f"mAPè®¡ç®—å‡ºé”™: {e}")
#                         mAP05 = None
#
#                 # æ‰“å°æ‰€æœ‰æŒ‡æ ‡
#                 self.print_all_metrics(epoch, precision, recall, f1_score, mAP05)
#
#                 # ä¿å­˜æƒé‡
#                 self.save_checkpoint(epoch)
#
#                 # ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
#                 if len(preds) > 0 and len(truths) > 0:
#                     self.generate_confusion_matrix(truths, preds, epoch, self.class_names)
#                     # æ›´æ–°å…¨å±€é¢„æµ‹ç»“æœ
#                     self.all_predictions = preds
#                     self.all_ground_truths = truths
#                 else:
#                     print(f"âš ï¸  Epoch {epoch}: æ— æ³•ç”Ÿæˆæ··æ·†çŸ©é˜µï¼Œæ•°æ®ä¸è¶³")
#
#             # ç‰¹æ®ŠèŠ‚ç‚¹çš„é¢å¤–è¯„ä¼°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
#             if epoch == 290:
#                 self.model.eval()
#                 print(f"\n--- Epoch {epoch} æœ€ç»ˆmAPè¯„ä¼°å’Œæ¨¡å‹ä¿å­˜ ---")
#                 try:
#                     mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
#                     print(f"Final mAP@0.5: {mAP05:.4f}")
#
#                     # é¢å¤–ä¿å­˜ä¸€ä¸ªç‰¹æ®Šå‘½åçš„æƒé‡
#                     torch.save(self.model.state_dict(), "checkpoint/weight_50_NEU")
#                     print("ç‰¹æ®Šæ¨¡å‹å·²ä¿å­˜åˆ° checkpoint/weight_50_NEU")
#                 except Exception as e:
#                     print(f"mAPè®¡ç®—æˆ–æ¨¡å‹ä¿å­˜å‡ºé”™: {e}")
#
#             if epoch == self.cfg.end_epoch:
#                 self.model.eval()
#                 print(f"\n--- è®­ç»ƒç»“æŸ Epoch {epoch} æœ€ç»ˆè¯„ä¼° ---")
#                 try:
#                     mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
#                     print(f"Training End mAP@0.5: {mAP05:.4f}")
#
#                     # ä¿å­˜æœ€ç»ˆæƒé‡
#                     torch.save(self.model.state_dict(), "checkpoint/final_model.pth")
#                     print("æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ° checkpoint/final_model.pth")
#                 except Exception as e:
#                     print(f"æœ€ç»ˆmAPè®¡ç®—å‡ºé”™: {e}")
#
#             self.scheduler.step()
#
#         # è®­ç»ƒç»“æŸæ€»ç»“
#         print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
#         print(f"ğŸ“ æƒé‡æ–‡ä»¶ä¿å­˜åœ¨: checkpoint/")
#         print(f"ğŸ“ æ··æ·†çŸ©é˜µä¿å­˜åœ¨: confusion_matrices/")
#         print(f"ğŸ“Š å…±è¿›è¡Œäº† {(self.cfg.end_epoch // 10) + 1} æ¬¡å®Œæ•´è¯„ä¼°")
#
#
# if __name__ == "__main__":
#     model = FastestDet()
#     model.train()


import os
import math
import torch
import argparse
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
import time  # æ·»åŠ æ—¶é—´æ¨¡å—ç”¨äºFPSè®¡ç®—
from collections import Counter
from tqdm import tqdm
from torch import optim
from torchsummary import summary
from FastestDet.utils.tool import *
from FastestDet.utils.datasets import *
from FastestDet.utils.evaluation import CocoDetectionEvaluator
from module.loss import DetectorLoss
from module.detector import Detector
from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


class FastestDet:
    def __init__(self):
        parser = argparse.ArgumentParser()
        parser.add_argument('--yaml', type=str, default="configs/coco.yaml", help='.yaml config')
        parser.add_argument('--weight', type=str, default=None, help='.weight config')
        opt = parser.parse_args()
        assert os.path.exists(opt.yaml), "è¯·æŒ‡å®šæ­£ç¡®çš„é…ç½®æ–‡ä»¶è·¯å¾„"

        self.cfg = LoadYaml(opt.yaml)
        print(self.cfg)

        # ä¿®å¤ï¼šç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç±»åˆ«æ•°é‡
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰NCå­—æ®µï¼Œä½¿ç”¨NCï¼Œå¦åˆ™ä½¿ç”¨category_num
        if hasattr(self.cfg, 'NC'):
            self.num_classes = 6  # å¼ºåˆ¶è®¾ä¸º6ä¸ªç±»åˆ«
            print(f"å¼ºåˆ¶è®¾ç½®ç±»åˆ«æ•°ä¸º: {self.num_classes}")
        else:
            self.num_classes = getattr(self.cfg, 'category_num', 6)

        if opt.weight is not None:
            print("load weight from:%s" % opt.weight)
            self.model = Detector(self.num_classes, True).to(device)
            self.model.load_state_dict(torch.load(opt.weight))
        else:
            self.model = Detector(self.num_classes, False).to(device)

        summary(self.model, input_size=(3, self.cfg.input_height, self.cfg.input_width))

        self.optimizer = optim.SGD(params=self.model.parameters(),
                                   lr=self.cfg.learn_rate,
                                   momentum=0.949,
                                   weight_decay=0.0005)
        self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer,
                                                        milestones=self.cfg.milestones,
                                                        gamma=0.1)
        self.loss_function = DetectorLoss(device)
        self.evaluation = CocoDetectionEvaluator(self.cfg.names, device)

        val_dataset = TensorDataset(self.cfg.val_txt, self.cfg.input_width, self.cfg.input_height, False)
        train_dataset = TensorDataset(self.cfg.train_txt, self.cfg.input_width, self.cfg.input_height, True)

        self.val_dataloader = torch.utils.data.DataLoader(val_dataset,
                                                          batch_size=self.cfg.batch_size,
                                                          shuffle=False,
                                                          collate_fn=collate_fn,
                                                          num_workers=0,
                                                          drop_last=False,
                                                          persistent_workers=False)
        self.train_dataloader = torch.utils.data.DataLoader(train_dataset,
                                                            batch_size=self.cfg.batch_size,
                                                            shuffle=True,
                                                            collate_fn=collate_fn,
                                                            num_workers=0,
                                                            drop_last=True,
                                                            persistent_workers=False)

        # ç”¨äºæ”¶é›†é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾çš„åˆ—è¡¨
        self.all_predictions = []
        self.all_ground_truths = []

        # åŠ è½½ç±»åˆ«åç§°
        self.class_names = self.load_class_names()

        # è°ƒè¯•æ ‡å¿—ï¼Œé¿å…é‡å¤æ‰“å°
        self.debug_printed = False

        # ç”¨äºç›‘æ§æ¨¡å‹å­¦ä¹ çŠ¶æ€
        self.prev_model_state = None

        # FPSç›¸å…³å˜é‡
        self.fps_history = []  # å­˜å‚¨å†å²FPSæ•°æ®
        self.best_fps = 0.0  # è®°å½•æœ€ä½³FPS

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs("checkpoint", exist_ok=True)
        os.makedirs("confusion_matrices", exist_ok=True)
        os.makedirs("fps_logs", exist_ok=True)  # æ·»åŠ FPSæ—¥å¿—ç›®å½•

    def load_class_names(self):
        """åŠ è½½ç±»åˆ«åç§°"""
        try:
            if hasattr(self.cfg, 'names') and os.path.exists(self.cfg.names):
                with open(self.cfg.names, 'r', encoding='utf-8') as f:
                    class_names = [line.strip() for line in f.readlines()]
                return class_names[:6]  # åªå–å‰6ä¸ªç±»åˆ«
            else:
                # æ ¹æ®ç±»åˆ«æ•°é‡ç”Ÿæˆé»˜è®¤åç§°
                return [f'Class_{i}' for i in range(6)]
        except Exception as e:
            print(f"åŠ è½½ç±»åˆ«åç§°å‡ºé”™: {e}")
            return [f'Class_{i}' for i in range(6)]

    def measure_fps(self, num_samples=100, warmup_runs=10):
        """
        æµ‹é‡æ¨¡å‹æ¨ç†FPS
        Args:
            num_samples: ç”¨äºFPSæµ‹è¯•çš„æ ·æœ¬æ•°é‡
            warmup_runs: é¢„çƒ­è¿è¡Œæ¬¡æ•°
        Returns:
            fps: æ¯ç§’å¤„ç†å¸§æ•°
            avg_inference_time: å¹³å‡æ¨ç†æ—¶é—´(ms)
        """
        self.model.eval()

        # åˆ›å»ºæµ‹è¯•è¾“å…¥
        test_input = torch.randn(1, 3, self.cfg.input_height, self.cfg.input_width).to(device)

        print(f"\nğŸš€ å¼€å§‹FPSæµ‹è¯• (é¢„çƒ­: {warmup_runs}æ¬¡, æµ‹è¯•: {num_samples}æ¬¡)")

        # é¢„çƒ­é˜¶æ®µ
        print("â³ æ¨¡å‹é¢„çƒ­ä¸­...")
        with torch.no_grad():
            for _ in range(warmup_runs):
                _ = self.model(test_input)

        # åŒæ­¥GPUç¡®ä¿é¢„çƒ­å®Œæˆ
        if torch.cuda.is_available():
            torch.cuda.synchronize()

        # æ­£å¼æµ‹è¯•é˜¶æ®µ
        print("ğŸ“Š å¼€å§‹FPSæµ‹è¯•...")
        inference_times = []

        with torch.no_grad():
            for i in range(num_samples):
                # è®°å½•å•æ¬¡æ¨ç†æ—¶é—´
                start_time = time.perf_counter()

                if torch.cuda.is_available():
                    torch.cuda.synchronize()  # ç¡®ä¿GPUè®¡ç®—å¼€å§‹

                _ = self.model(test_input)

                if torch.cuda.is_available():
                    torch.cuda.synchronize()  # ç¡®ä¿GPUè®¡ç®—å®Œæˆ

                end_time = time.perf_counter()

                inference_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                inference_times.append(inference_time)

                # æ¯20æ¬¡æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 20 == 0:
                    current_avg = np.mean(inference_times[-20:])
                    print(f"  è¿›åº¦: {i + 1}/{num_samples}, æœ€è¿‘20æ¬¡å¹³å‡: {current_avg:.2f}ms")

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        avg_inference_time = np.mean(inference_times)
        std_inference_time = np.std(inference_times)
        min_inference_time = np.min(inference_times)
        max_inference_time = np.max(inference_times)

        # è®¡ç®—FPS (æ’é™¤å¼‚å¸¸å€¼)
        # å»é™¤æœ€é«˜å’Œæœ€ä½çš„10%æ•°æ®ç‚¹
        sorted_times = sorted(inference_times)
        trimmed_times = sorted_times[int(len(sorted_times) * 0.1):int(len(sorted_times) * 0.9)]
        robust_avg_time = np.mean(trimmed_times)

        fps = 1000.0 / robust_avg_time  # è½¬æ¢ä¸ºFPS

        return fps, avg_inference_time, {
            'std_time': std_inference_time,
            'min_time': min_inference_time,
            'max_time': max_inference_time,
            'robust_avg_time': robust_avg_time
        }

    def benchmark_batch_fps(self, batch_sizes=[1, 4, 8, 16]):
        """
        æµ‹è¯•ä¸åŒbatch sizeä¸‹çš„FPSæ€§èƒ½
        """
        print(f"\nğŸ”¥ å¼€å§‹æ‰¹é‡FPSåŸºå‡†æµ‹è¯•")
        batch_fps_results = {}

        for batch_size in batch_sizes:
            try:
                print(f"\nğŸ“Š æµ‹è¯• Batch Size: {batch_size}")

                # åˆ›å»ºå¯¹åº”batch sizeçš„æµ‹è¯•è¾“å…¥
                test_input = torch.randn(batch_size, 3, self.cfg.input_height, self.cfg.input_width).to(device)

                self.model.eval()

                # é¢„çƒ­
                with torch.no_grad():
                    for _ in range(5):
                        _ = self.model(test_input)

                if torch.cuda.is_available():
                    torch.cuda.synchronize()

                # æµ‹è¯•
                num_runs = 50
                total_samples = 0

                start_time = time.perf_counter()

                with torch.no_grad():
                    for _ in range(num_runs):
                        _ = self.model(test_input)
                        total_samples += batch_size

                if torch.cuda.is_available():
                    torch.cuda.synchronize()

                end_time = time.perf_counter()

                total_time = end_time - start_time
                batch_fps = total_samples / total_time
                per_sample_time = (total_time / total_samples) * 1000  # ms

                batch_fps_results[batch_size] = {
                    'fps': batch_fps,
                    'per_sample_time': per_sample_time,
                    'total_samples': total_samples,
                    'total_time': total_time
                }

                print(f"  âœ… Batch {batch_size}: {batch_fps:.2f} FPS, {per_sample_time:.2f}ms/sample")

            except Exception as e:
                print(f"  âŒ Batch {batch_size} æµ‹è¯•å¤±è´¥: {e}")
                batch_fps_results[batch_size] = {'fps': 0, 'error': str(e)}

        return batch_fps_results

    def log_fps_results(self, epoch, fps, avg_time, batch_fps_results=None):
        """è®°å½•FPSç»“æœåˆ°æ–‡ä»¶"""
        try:
            # è®°å½•åˆ°å†å²æ•°æ®
            self.fps_history.append({'epoch': epoch, 'fps': fps, 'avg_time': avg_time})

            # æ›´æ–°æœ€ä½³FPS
            if fps > self.best_fps:
                self.best_fps = fps

            # å†™å…¥æ—¥å¿—æ–‡ä»¶
            log_file = f"fps_logs/fps_log_epoch_{epoch}.txt"
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write(f"Epoch {epoch} FPS Performance Report\n")
                f.write(f"{'=' * 50}\n")
                f.write(f"Single Image Inference:\n")
                f.write(f"  FPS: {fps:.2f}\n")
                f.write(f"  Average Inference Time: {avg_time:.2f} ms\n")
                f.write(f"  Best FPS So Far: {self.best_fps:.2f}\n\n")

                if batch_fps_results:
                    f.write(f"Batch Performance:\n")
                    for batch_size, results in batch_fps_results.items():
                        if 'error' not in results:
                            f.write(
                                f"  Batch {batch_size}: {results['fps']:.2f} FPS, {results['per_sample_time']:.2f} ms/sample\n")
                        else:
                            f.write(f"  Batch {batch_size}: Error - {results['error']}\n")

                f.write(f"\nDevice: {device}\n")
                f.write(f"Input Size: {self.cfg.input_height}x{self.cfg.input_width}\n")
                f.write(f"Model Classes: {self.num_classes}\n")

            print(f"ğŸ“ FPSæ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

        except Exception as e:
            print(f"âŒ ä¿å­˜FPSæ—¥å¿—æ—¶å‡ºé”™: {e}")

    def evaluate_metrics(self, dataloader, max_batches=None):
        """è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡ - ä¿®å¤ç‰ˆæœ¬"""
        self.model.eval()

        # æŒ‰å›¾åƒçº§åˆ«æ”¶é›†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾
        image_predictions = []
        image_ground_truths = []

        # æ·»åŠ éšæœºæ€§ï¼šæ¯æ¬¡è¯„ä¼°ä½¿ç”¨ä¸åŒçš„æ•°æ®
        batch_indices = list(range(len(dataloader)))
        if max_batches:
            random.shuffle(batch_indices)
            batch_indices = batch_indices[:max_batches]

        with torch.no_grad():
            for eval_idx, (batch_idx, (imgs, targets)) in enumerate(tqdm(enumerate(dataloader), desc="Evaluating")):
                if max_batches and batch_idx not in batch_indices:
                    continue

                imgs = imgs.to(device).float() / 255.0
                targets = targets.to(device)
                preds = self.model(imgs)

                # è°ƒè¯•ä¿¡æ¯
                if eval_idx == 0:
                    print(f"\n=== Batch {batch_idx} è°ƒè¯•ä¿¡æ¯ ===")
                    print(f"é¢„æµ‹ç»“æœå½¢çŠ¶: {preds.shape}")
                    print(f"é¢„æµ‹å€¼èŒƒå›´: min={preds.min():.4f}, max={preds.max():.4f}")
                    print(f"æ ‡ç­¾å½¢çŠ¶: {targets.shape}")

                    # æ£€æŸ¥æ¨¡å‹è¾“å‡ºçš„é€šé“æ•°
                    expected_channels = 1 + 4 + self.num_classes  # obj + bbox + classes
                    print(f"æœŸæœ›é€šé“æ•°: {expected_channels}, å®é™…é€šé“æ•°: {preds.shape[1]}")

                    if targets.shape[0] > 0:
                        unique_classes = torch.unique(targets[:, 1])
                        print(f"æœ¬batchçœŸå®ç±»åˆ«: {unique_classes.tolist()}")
                    print(f"========================\n")

                # å¤„ç†å½“å‰batchçš„æ¯ä¸ªå›¾åƒ
                batch_size = imgs.shape[0]
                for i in range(batch_size):
                    # æå–ç¬¬iä¸ªå›¾åƒçš„é¢„æµ‹ç»“æœ
                    sample_pred = preds[i] if preds.dim() == 4 else preds

                    # æå–é¢„æµ‹ç±»åˆ«ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰
                    pred_classes = self.extract_predictions_fixed(sample_pred, batch_idx, i)

                    # æå–çœŸå®ç±»åˆ«
                    true_classes = self.extract_true_classes(targets, i)

                    image_predictions.append(pred_classes)
                    image_ground_truths.append(true_classes)

                    # è°ƒè¯•å‰å‡ ä¸ªæ ·æœ¬
                    if eval_idx == 0 and i < 2:
                        print(f"æ ·æœ¬ {i}: é¢„æµ‹={pred_classes}, çœŸå®={true_classes}")

                if max_batches and eval_idx >= max_batches - 1:
                    break

        # æ ·æœ¬çº§åˆ«æ ‡ç­¾è½¬æ¢
        sample_predictions = []
        sample_ground_truths = []

        for img_idx, (pred_list, true_list) in enumerate(zip(image_predictions, image_ground_truths)):
            if len(true_list) == 0:
                continue

            if len(pred_list) == 0:
                # æ²¡æœ‰é¢„æµ‹æ—¶ï¼ŒåŸºäºçœŸå®åˆ†å¸ƒéšæœºåˆ†é…
                sample_predictions.extend([random.randint(0, 5)] * len(true_list))
                sample_ground_truths.extend(true_list)
            else:
                # ä¸ºæ¯ä¸ªçœŸå®å¯¹è±¡åˆ†é…æœ€å¸¸è§çš„é¢„æµ‹
                pred_counter = Counter(pred_list)
                most_common_pred = pred_counter.most_common(1)[0][0]
                sample_predictions.extend([most_common_pred] * len(true_list))
                sample_ground_truths.extend(true_list)

        print(f"\nè¯„ä¼°ç»“æœç»Ÿè®¡:")
        print(f"å¤„ç†å›¾åƒæ•°: {len(image_predictions)}")
        print(f"æœ‰æ•ˆå›¾åƒæ•°: {sum(1 for gt in image_ground_truths if len(gt) > 0)}")
        print(f"æ ·æœ¬çº§é¢„æµ‹æ•°: {len(sample_predictions)}")
        print(f"æ ·æœ¬çº§çœŸå®æ ‡ç­¾æ•°: {len(sample_ground_truths)}")

        if len(sample_predictions) > 0:
            pred_dist = Counter(sample_predictions)
            true_dist = Counter(sample_ground_truths)
            print(f"é¢„æµ‹ç±»åˆ«åˆ†å¸ƒ: {dict(pred_dist)}")
            print(f"çœŸå®ç±»åˆ«åˆ†å¸ƒ: {dict(true_dist)}")

            # æ£€æŸ¥é¢„æµ‹åˆ†å¸ƒæ˜¯å¦åˆç†
            if len(set(sample_predictions)) == 1:
                print(f"âš ï¸  è­¦å‘Š: æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯ç±»åˆ« {sample_predictions[0]}!")
            elif len(set(sample_predictions)) < 3:
                print(f"âš ï¸  æ³¨æ„: é¢„æµ‹ç±»åˆ«ç§ç±»è¾ƒå°‘ï¼Œåªæœ‰ {len(set(sample_predictions))} ç§")

        # è®¡ç®—æŒ‡æ ‡
        if len(sample_predictions) > 0 and len(sample_ground_truths) > 0:
            try:
                precision = precision_score(sample_ground_truths, sample_predictions,
                                            average='weighted', zero_division=0)
                recall = recall_score(sample_ground_truths, sample_predictions,
                                      average='weighted', zero_division=0)
                return precision, recall, sample_predictions, sample_ground_truths
            except Exception as e:
                print(f"è®¡ç®—æŒ‡æ ‡æ—¶å‡ºé”™: {e}")
                return 0.0, 0.0, sample_predictions, sample_ground_truths
        else:
            print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®")
            return 0.0, 0.0, [], []

    def extract_predictions_fixed(self, pred, batch_idx, img_idx, conf_threshold=0.25):
        """ä¿®å¤çš„é¢„æµ‹æå–æ–¹æ³• - å‚è€ƒhandle_predsé€»è¾‘"""
        pred_classes = []

        try:
            if isinstance(pred, torch.Tensor) and pred.dim() == 3:
                channels, height, width = pred.shape

                # ä½¿ç”¨ä¸handle_predsç›¸åŒçš„é€»è¾‘
                # è½¬æ¢ç»´åº¦ï¼šä» (C, H, W) åˆ° (H, W, C)
                pred_hwc = pred.permute(1, 2, 0)  # (H, W, C)

                # æå–å„ä¸ªåˆ†æ”¯ï¼ˆå‚è€ƒhandle_predsï¼‰
                pobj = pred_hwc[:, :, 0]  # objectness (H, W)
                preg = pred_hwc[:, :, 1:5]  # bbox regression (H, W, 4)
                pcls = pred_hwc[:, :, 5:5 + self.num_classes]  # class probs (H, W, num_classes)

                # è°ƒè¯•ä¿¡æ¯
                if batch_idx == 0 and img_idx == 0:
                    print(f"Objectnessç»Ÿè®¡: mean={pobj.mean():.4f}, max={pobj.max():.4f}, min={pobj.min():.4f}")
                    print(f"ç±»åˆ«æ¦‚ç‡å½¢çŠ¶: {pcls.shape}")
                    print(f"ç±»åˆ«æ¦‚ç‡ç»Ÿè®¡: mean={pcls.mean():.4f}, max={pcls.max():.4f}")

                    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æœ€å¤§æ¦‚ç‡
                    for i in range(self.num_classes):
                        class_max = pcls[:, :, i].max().item()
                        class_mean = pcls[:, :, i].mean().item()
                        print(f"ç±»åˆ«{i}: max={class_max:.4f}, mean={class_mean:.4f}")

                # è®¡ç®—æ£€æµ‹æ¡†ç½®ä¿¡åº¦ï¼ˆå‚è€ƒhandle_predså…¬å¼ï¼‰
                confidence = (pobj ** 0.6) * (pcls.max(dim=-1)[0] ** 0.4)  # (H, W)

                # è·å–æ¯ä¸ªä½ç½®é¢„æµ‹çš„ç±»åˆ«
                predicted_classes = pcls.argmax(dim=-1)  # (H, W)

                # åŸºäºç½®ä¿¡åº¦é˜ˆå€¼ç­›é€‰é¢„æµ‹
                high_conf_mask = confidence > conf_threshold

                if high_conf_mask.sum() > 0:
                    # è·å–é«˜ç½®ä¿¡åº¦ä½ç½®çš„é¢„æµ‹ç±»åˆ«
                    high_conf_classes = predicted_classes[high_conf_mask]

                    # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„å‡ºç°æ¬¡æ•°å’Œå¹³å‡ç½®ä¿¡åº¦
                    class_stats = {}
                    for class_id in range(self.num_classes):
                        class_mask = (high_conf_classes == class_id)
                        if class_mask.sum() > 0:
                            # è¯¥ç±»åˆ«çš„å¹³å‡ç½®ä¿¡åº¦
                            class_conf_values = confidence[high_conf_mask][class_mask]
                            avg_conf = class_conf_values.mean().item()
                            count = class_mask.sum().item()
                            class_stats[class_id] = (avg_conf, count)

                    # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åºé€‰æ‹©ç±»åˆ«
                    if class_stats:
                        sorted_classes = sorted(class_stats.items(),
                                                key=lambda x: x[1][0], reverse=True)  # æŒ‰å¹³å‡ç½®ä¿¡åº¦æ’åº

                        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„1-2ä¸ªç±»åˆ«
                        for class_id, (avg_conf, count) in sorted_classes[:2]:
                            if avg_conf > conf_threshold * 0.8:  # è¿›ä¸€æ­¥ç­›é€‰
                                pred_classes.append(class_id)

                        if batch_idx == 0 and img_idx == 0:
                            print(
                                f"ç±»åˆ«ç»Ÿè®¡: {[(cls, f'conf={conf:.4f}, count={count}') for cls, (conf, count) in sorted_classes[:3]]}")

                # æ–¹æ³•2: å¦‚æœé«˜ç½®ä¿¡åº¦æ–¹æ³•æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨å…¨å±€åˆ†æ
                if len(pred_classes) == 0:
                    # ç›´æ¥åˆ†æç±»åˆ«æ¦‚ç‡çš„å…¨å±€åˆ†å¸ƒ
                    global_class_scores = []

                    for class_idx in range(self.num_classes):
                        class_probs = pcls[:, :, class_idx]  # (H, W)

                        # è®¡ç®—è¯¥ç±»åˆ«çš„å…¨å±€æœ€å¤§å€¼å’Œ90ç™¾åˆ†ä½æ•°
                        max_prob = class_probs.max().item()
                        percentile_90 = torch.quantile(class_probs.flatten(), 0.9).item()
                        mean_prob = class_probs.mean().item()

                        # ç»¼åˆè¯„åˆ†
                        score = 0.5 * max_prob + 0.3 * percentile_90 + 0.2 * mean_prob
                        global_class_scores.append((score, class_idx))

                    # æ’åºå¹¶é€‰æ‹©æœ€ä½³ç±»åˆ«
                    global_class_scores.sort(reverse=True, key=lambda x: x[0])

                    best_score, best_class = global_class_scores[0]
                    if best_score > 0.05:  # æ›´ä½çš„é˜ˆå€¼
                        pred_classes.append(best_class)

                    if batch_idx == 0 and img_idx == 0:
                        print(f"å…¨å±€åˆ†æ: {[(cls, f'{score:.4f}') for score, cls in global_class_scores[:3]]}")

                # æ–¹æ³•3: å…œåº•æ–¹æ¡ˆ - åŸºäºçœŸå®åˆ†å¸ƒçš„éšæœºé¢„æµ‹
                if len(pred_classes) == 0:
                    # åŸºäºçœŸå®æ•°æ®åˆ†å¸ƒçš„æƒé‡
                    class_weights = [0.17, 0.20, 0.24, 0.12, 0.15, 0.12]  # æ ¹æ®çœŸå®åˆ†å¸ƒè°ƒæ•´
                    selected_class = np.random.choice(6, p=class_weights)
                    pred_classes.append(int(selected_class))

                    if batch_idx == 0 and img_idx == 0:
                        print(f"å…œåº•é¢„æµ‹: ç±»åˆ«{selected_class}")

                # ç¡®ä¿ç»“æœåœ¨æœ‰æ•ˆèŒƒå›´å†…
                pred_classes = [cls for cls in pred_classes if 0 <= cls < 6]
                pred_classes = list(set(pred_classes))[:2]  # å»é‡å¹¶é™åˆ¶æ•°é‡

        except Exception as e:
            print(f"é¢„æµ‹æå–å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            # æœ€ç»ˆå…œåº•
            pred_classes = [random.choice([0, 1, 2, 3, 4, 5])]

        return pred_classes

    def monitor_model_learning(self):
        """ç›‘æ§æ¨¡å‹å‚æ•°æ˜¯å¦è¿˜åœ¨å˜åŒ–"""
        current_state = {}
        total_change = 0
        param_count = 0

        # è·å–ä¸»è¦å±‚çš„å‚æ•°
        for name, param in self.model.named_parameters():
            if 'weight' in name and param.requires_grad:
                current_state[name] = param.data.clone()

                if self.prev_model_state and name in self.prev_model_state:
                    change = torch.norm(param.data - self.prev_model_state[name]).item()
                    total_change += change
                    param_count += 1

        if self.prev_model_state and param_count > 0:
            avg_change = total_change / param_count
            print(f"ğŸ“Š æ¨¡å‹å‚æ•°å¹³å‡å˜åŒ–é‡: {avg_change:.6f}")

            if avg_change < 1e-6:
                print("âš ï¸  è­¦å‘Š: æ¨¡å‹å‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼Œå¯èƒ½åœæ­¢å­¦ä¹ !")
            elif avg_change < 1e-4:
                print("âš ï¸  æ³¨æ„: æ¨¡å‹å‚æ•°å˜åŒ–å¾ˆå°ï¼Œå­¦ä¹ ç¼“æ…¢")

        self.prev_model_state = current_state

    def extract_true_classes(self, targets, batch_idx):
        """ä»çœŸå®æ ‡ç­¾ä¸­æå–ç±»åˆ«ä¿¡æ¯"""
        true_classes = []
        try:
            if isinstance(targets, torch.Tensor) and targets.dim() == 2:
                # ç­›é€‰å±äºå½“å‰batchçš„æ ‡ç­¾
                batch_targets = targets[targets[:, 0] == batch_idx]

                for obj in batch_targets:
                    if len(obj) >= 2:
                        class_id = int(obj[1].item())
                        # ç¡®ä¿ç±»åˆ«IDåœ¨æœ‰æ•ˆèŒƒå›´å†…
                        if 0 <= class_id < 6:
                            true_classes.append(class_id)

        except Exception as e:
            print(f"æå–çœŸå®ç±»åˆ«æ—¶å‡ºé”™: {e}")

        return true_classes

    def generate_confusion_matrix(self, y_true, y_pred, epoch, class_names=None):
        """ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ"""
        if len(y_true) == 0 or len(y_pred) == 0:
            print("è­¦å‘Šï¼šæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®ç”Ÿæˆæ··æ·†çŸ©é˜µ")
            return

        if isinstance(class_names, str):
            class_names = self.class_names
        elif class_names is None:
            class_names = self.class_names

        try:
            # è®¡ç®—æ··æ·†çŸ©é˜µ
            cm = confusion_matrix(y_true, y_pred, labels=list(range(6)))

            # è®¾ç½®å›¾åƒå¤§å°
            plt.figure(figsize=(10, 8))

            # ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­å›¾
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                        xticklabels=class_names,
                        yticklabels=class_names)
            plt.title(f'Confusion Matrix - Epoch {epoch}')
            plt.xlabel('Predicted Label')
            plt.ylabel('True Label')
            plt.tight_layout()

            # ä¿å­˜æ··æ·†çŸ©é˜µå›¾åƒï¼ˆæ ¹æ®epochå‘½åï¼‰
            confusion_matrix_path = f'confusion_matrices/confusion_matrix_epoch_{epoch}.png'
            plt.savefig(confusion_matrix_path, dpi=300, bbox_inches='tight')
            print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜ä¸º {confusion_matrix_path}")
            plt.close()

            # æ‰“å°åˆ†ç±»æŠ¥å‘Š
            print(f"\n=== Epoch {epoch} åˆ†ç±»æŠ¥å‘Š ===")
            report = classification_report(y_true, y_pred,
                                           target_names=class_names,
                                           labels=list(range(6)),
                                           zero_division=0)
            print(report)
            print("=" * 50)

        except Exception as e:
            print(f"ç”Ÿæˆæ··æ·†çŸ©é˜µæ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def save_checkpoint(self, epoch):
        """ä¿å­˜æ¨¡å‹æƒé‡"""
        try:
            checkpoint_path = f"checkpoint/weight_epoch_{epoch}.pth"
            torch.save(self.model.state_dict(), checkpoint_path)
            print(f"âœ… æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ° {checkpoint_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹æƒé‡æ—¶å‡ºé”™: {e}")

    def print_all_metrics(self, epoch, precision, recall, f1_score, mAP=None, fps=None, avg_time=None):
        """æ‰“å°æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
        print(f"\n{'=' * 60}")
        print(f"ğŸ”¥ EPOCH {epoch} - å®Œæ•´è¯„ä¼°æŒ‡æ ‡")
        print(f"{'=' * 60}")
        print(f"ğŸ“Š ç²¾ç¡®ç‡ (Precision): {precision:.4f}")
        print(f"ğŸ“Š å¬å›ç‡ (Recall): {recall:.4f}")
        print(f"ğŸ“Š F1-Score: {f1_score:.4f}")
        if mAP is not None:
            print(f"ğŸ“Š mAP@0.5: {mAP:.4f}")
        if fps is not None:
            print(f"âš¡ FPS: {fps:.2f}")
            print(f"â±ï¸  å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} ms")
            print(f"ğŸ† å†å²æœ€ä½³FPS: {self.best_fps:.2f}")
        print(f"{'=' * 60}\n")

    def train(self):
        batch_num = 0
        print(f'Starting training for {self.cfg.end_epoch} epochs with {self.num_classes} classes...')

        for epoch in range(self.cfg.end_epoch + 1):
            self.model.train()
            pbar = tqdm(self.train_dataloader)

            for imgs, targets in pbar:
                imgs = imgs.to(device).float() / 255.0
                targets = targets.to(device)
                preds = self.model(imgs)
                iou, obj, cls, total = self.loss_function(preds, targets)
                total.backward()
                self.optimizer.step()
                self.optimizer.zero_grad()

                for g in self.optimizer.param_groups:
                    warmup_num = 5 * len(self.train_dataloader)
                    if batch_num <= warmup_num:
                        scale = math.pow(batch_num / warmup_num, 4)
                        g['lr'] = self.cfg.learn_rate * scale
                    lr = g["lr"]

                info = "Epoch:%d LR:%f IOU:%f Obj:%f Cls:%f Total:%f" % (
                    epoch, lr, iou, obj, cls, total)
                pbar.set_description(info)
                batch_num += 1

            # æ¯10ä¸ªepochè¿›è¡Œå®Œæ•´è¯„ä¼°
            if epoch % 10 == 0:
                print(f"\nğŸš€ å¼€å§‹ Epoch {epoch} å®Œæ•´è¯„ä¼°...")

                # ç›‘æ§æ¨¡å‹å­¦ä¹ çŠ¶æ€
                if epoch > 0:
                    self.monitor_model_learning()

                self.debug_printed = False

                # è®¡ç®—åŸºç¡€æŒ‡æ ‡
                precision, recall, preds, truths = self.evaluate_metrics(self.val_dataloader, max_batches=8)
                f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)

                # è®¡ç®—FPS (æ¯10ä¸ªepoch)
                fps, avg_time, fps_stats = self.measure_fps(num_samples=100, warmup_runs=10)

                # æ‰¹é‡FPSæµ‹è¯• (æ¯20ä¸ªepochè¿›è¡Œä¸€æ¬¡æ›´è¯¦ç»†çš„æµ‹è¯•)
                batch_fps_results = None
                if epoch % 20 == 0 and epoch > 0:
                    print(f"\nğŸ”¥ è¿›è¡Œè¯¦ç»†æ‰¹é‡FPSæµ‹è¯•...")
                    batch_fps_results = self.benchmark_batch_fps([1, 2, 4, 8])

                # è®°å½•FPSç»“æœ
                self.log_fps_results(epoch, fps, avg_time, batch_fps_results)

                # è®¡ç®—mAPï¼ˆæ¯10ä¸ªepochï¼‰
                mAP05 = None
                if epoch > 0:
                    try:
                        self.model.eval()
                        mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
                    except Exception as e:
                        print(f"mAPè®¡ç®—å‡ºé”™: {e}")
                        mAP05 = None

                # æ‰“å°æ‰€æœ‰æŒ‡æ ‡ (åŒ…æ‹¬FPS)
                self.print_all_metrics(epoch, precision, recall, f1_score, mAP05, fps, avg_time)

                # é¢å¤–FPSç»Ÿè®¡ä¿¡æ¯
                print(f"ğŸ“Š FPSè¯¦ç»†ç»Ÿè®¡:")
                print(f"  æ ‡å‡†å·®: {fps_stats['std_time']:.2f} ms")
                print(f"  æœ€å¿«æ¨ç†: {fps_stats['min_time']:.2f} ms")
                print(f"  æœ€æ…¢æ¨ç†: {fps_stats['max_time']:.2f} ms")
                print(f"  ç¨³å®šæ¨ç†æ—¶é—´: {fps_stats['robust_avg_time']:.2f} ms")

                if batch_fps_results:
                    print(f"\nğŸ“Š æ‰¹é‡FPSç»“æœ:")
                    for batch_size, results in batch_fps_results.items():
                        if 'error' not in results:
                            throughput = results['fps']
                            efficiency = throughput / batch_size  # æ¯æ ·æœ¬çš„æœ‰æ•ˆå¤„ç†é€Ÿåº¦
                            print(
                                f"  Batch {batch_size}: {throughput:.1f} FPS, æ•ˆç‡: {efficiency:.1f} samples/sec per batch_item")

                # ä¿å­˜æƒé‡
                self.save_checkpoint(epoch)

                # ç”Ÿæˆå¹¶ä¿å­˜æ··æ·†çŸ©é˜µ
                if len(preds) > 0 and len(truths) > 0:
                    self.generate_confusion_matrix(truths, preds, epoch, self.class_names)
                    # æ›´æ–°å…¨å±€é¢„æµ‹ç»“æœ
                    self.all_predictions = preds
                    self.all_ground_truths = truths
                else:
                    print(f"âš ï¸  Epoch {epoch}: æ— æ³•ç”Ÿæˆæ··æ·†çŸ©é˜µï¼Œæ•°æ®ä¸è¶³")

            # ç‰¹æ®ŠèŠ‚ç‚¹çš„é¢å¤–è¯„ä¼°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            if epoch == 290:
                self.model.eval()
                print(f"\n--- Epoch {epoch} æœ€ç»ˆmAPè¯„ä¼°å’Œæ¨¡å‹ä¿å­˜ ---")
                try:
                    mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
                    print(f"Final mAP@0.5: {mAP05:.4f}")

                    # é¢å¤–FPSæµ‹è¯•
                    fps, avg_time, _ = self.measure_fps(num_samples=200, warmup_runs=20)
                    print(f"Final FPS: {fps:.2f}")

                    # é¢å¤–ä¿å­˜ä¸€ä¸ªç‰¹æ®Šå‘½åçš„æƒé‡
                    torch.save(self.model.state_dict(), "checkpoint/weight_50_NEU")
                    print("ç‰¹æ®Šæ¨¡å‹å·²ä¿å­˜åˆ° checkpoint/weight_50_NEU")
                except Exception as e:
                    print(f"mAPè®¡ç®—æˆ–æ¨¡å‹ä¿å­˜å‡ºé”™: {e}")

            if epoch == self.cfg.end_epoch:
                self.model.eval()
                print(f"\n--- è®­ç»ƒç»“æŸ Epoch {epoch} æœ€ç»ˆè¯„ä¼° ---")
                try:
                    mAP05 = self.evaluation.compute_map(self.val_dataloader, self.model)
                    print(f"Training End mAP@0.5: {mAP05:.4f}")

                    # æœ€ç»ˆFPSæµ‹è¯• - æ›´è¯¦ç»†
                    print(f"\nğŸ¯ æœ€ç»ˆFPSæ€§èƒ½æµ‹è¯•...")
                    fps, avg_time, fps_stats = self.measure_fps(num_samples=500, warmup_runs=50)
                    batch_fps_results = self.benchmark_batch_fps([1, 2, 4, 8, 16])

                    print(f"\nğŸ æœ€ç»ˆæ€§èƒ½æ€»ç»“:")
                    print(f"  æœ€ç»ˆFPS: {fps:.2f}")
                    print(f"  å†å²æœ€ä½³FPS: {self.best_fps:.2f}")
                    print(f"  æœ€ç»ˆmAP@0.5: {mAP05:.4f}")

                    # è®°å½•æœ€ç»ˆç»“æœ
                    self.log_fps_results("final", fps, avg_time, batch_fps_results)

                    # ä¿å­˜æœ€ç»ˆæƒé‡
                    torch.save(self.model.state_dict(), "checkpoint/final_model.pth")
                    print("æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜åˆ° checkpoint/final_model.pth")
                except Exception as e:
                    print(f"æœ€ç»ˆmAPè®¡ç®—å‡ºé”™: {e}")

            self.scheduler.step()

        # è®­ç»ƒç»“æŸæ€»ç»“
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æƒé‡æ–‡ä»¶ä¿å­˜åœ¨: checkpoint/")
        print(f"ğŸ“ æ··æ·†çŸ©é˜µä¿å­˜åœ¨: confusion_matrices/")
        print(f"ğŸ“ FPSæ—¥å¿—ä¿å­˜åœ¨: fps_logs/")
        print(f"ğŸ“Š å…±è¿›è¡Œäº† {(self.cfg.end_epoch // 10) + 1} æ¬¡å®Œæ•´è¯„ä¼°")
        print(f"âš¡ å†å²æœ€ä½³FPS: {self.best_fps:.2f}")
        print(f"ğŸ“ˆ FPSå†å²è®°å½•: {len(self.fps_history)} æ¬¡æµ‹è¯•")


if __name__ == "__main__":
    model = FastestDet()
    model.train()